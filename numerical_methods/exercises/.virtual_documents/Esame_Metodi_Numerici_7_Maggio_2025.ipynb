








from scipy.io import loadmat
from SolveTriangular import *
import matplotlib.pyplot as plt
import numpy as np

dati = loadmat('test_7_maggio_2025')
A = dati["A"]
A = A.astype(float)
b = dati["b"]
b = b.astype(float)
A1 = dati["A1"]
A1 = A1.astype(float)
b1 = dati["b1"]
b1 = b1.astype(float)


m, n = A.shape
print("Dimensione A:", m, "x", n)
sp = np.count_nonzero(A) / (m * n)
print("Percentuale sparsità", sp)


flagS = A == A.T # A è simmetrica?

if np.all(flagS):
    print("A Matrice simmetrica")
else:
    print("A Matrice non simmetrica")


eigenvalue = np.linalg.eigvals(A) # A è def pos?

if np.all(eigenvalue) > 0:
    print("A Matrice definita positiva")


# Indice di condizionamento
condA = np.linalg.cond(A)
print("Indice di condizionamento A:", condA)


def steepestdescent(A, b, x0, itmax, tol):
    n, m = A.shape
    if n != m:
        print("Matrice non quadrata")
        return [], []    
    
    # inizializzare le variabili necessarie
    x = x0
    r = A@x - b
    p = -r
    it = 0
    nb = np.linalg.norm(b)
    errore = np.linalg.norm(r) / nb
    vec_sol = []
    vec_sol.append(x.copy())
    vet_r = []
    vet_r.append(errore)
     
    # utilizzare il metodo del gradiente per trovare la soluzione
    while errore >= tol and it < itmax:
        it = it+1
        Ap = A@p
        alpha = -(r.T@p) / (p.T@Ap)
        x = x + alpha * p
         
        vec_sol.append(x.copy())
        r = r + alpha * Ap
        errore = np.linalg.norm(r) / nb
        vet_r.append(errore)
        p = -r
        
    iterates_array = np.vstack([arr.T for arr in vec_sol])
    return x, vet_r, iterates_array, it


def conjugate_gradient(A, b, x0, itmax, tol):
    n, m = A.shape
    if n != m:
        print("Matrice non quadrata")
        return [], []    
    
    # inizializzare le variabili necessarie
    x = x0
    r = A@x - b
    p = -r
    it = 0
    nb = np.linalg.norm(b)
    errore = np.linalg.norm(r) / nb
    vec_sol = []
    vec_sol.append(x.copy())
    vet_r = []
    vet_r.append(errore)
     
    # utilizzare il metodo del gradiente per trovare la soluzione
    while errore >= tol and it < itmax:
        it = it+1
        Ap = A@p
        alpha = -(r.T@p) / (p.T@Ap)
        x = x + alpha * p
         
        vec_sol.append(x.copy())
        rtr_old = r.T@r
        r = r + alpha * Ap
        errore = np.linalg.norm(r) / nb
        vet_r.append(errore)
        gamma = r.T@r / rtr_old
        p = -r + gamma * p
        
    iterates_array = np.vstack([arr.T for arr in vec_sol])
    return x, vet_r, iterates_array, it


def gauss_seidel(A, b, x0, toll, itmax):
    errore = 1000
    d = np.diag(A)
    D = np.diag(d)
    E = np.tril(A, -1)
    F = np.triu(A, 1)
    M = D + E
    N = -F 
    T = np.linalg.inv(M)@N 
    autovalori = np.linalg.eigvals(T)
    raggiospettrale = np.max(np.abs(autovalori))
    print("raggio spettrale Gauss-Seidel", raggiospettrale)
    it = 0
    er_vet = []
    while errore >= tol and it < itmax:
        x = Lsolve(M, b - F@x0)
        errore = np.linalg.norm(x - x0) / np.linalg.norm(x)
        er_vet.append(errore)
        x0 = x.copy()
        it = it + 1
    return x, it, er_vet


x0 = np.zeros_like(b)
tol = 1e-6
itmax = 2000
x, vet_r, iterates_array, it = steepestdescent(A, b, x0, itmax, tol)
print("Numero iterazioni", it)
plt.semilogy(range(len(vet_r)), vet_r)
plt.show()
xCG, vet_rCG, iterates_arrayCG, itCG = conjugate_gradient(A, b, x0, itmax, tol)
print("Numero iterazioni", itCG)
plt.semilogy(range(len(vet_rCG)), vet_rCG)
plt.show()
xGS, itGS, vet_rGS = gauss_seidel(A, b, x0, itmax, tol)
print("Numero iterazioni", itGS)
plt.semilogy(range(len(vet_rGS)), vet_rGS)
plt.show()


condA1 = np.linalg.cond(A1)
print("Indice di condizionamento A1:", condA1)


x0_1 = np.zeros_like(b1)
x1, vet_r1, iterates_array1, it1 = steepestdescent(A1, b1, x0_1, itmax, tol)
print("Numero iterazioni", it1)
plt.semilogy(range(len(vet_r1)), vet_r1)
plt.show()

x1CG, vet_r1CG, iterates_array1CG, it1CG = conjugate_gradient(A1, b1, x0_1, itmax, tol)
print("Numero iterazioni", it1CG)
plt.semilogy(range(len(vet_r1CG)), vet_r1CG)
plt.show()








import numpy as np
import scipy as sp
import matplotlib.pyplot as plt
import math
from SolveTriangular import *
M = np.array([[1, 1, 1], [4, 0, 1], [0, 4, 1]])
b = np.array([-2, -16, -16]).T
pxi = np.array([1, 4, 0])
pyi = np.array([1, 0, 4])


condM = np.linalg.cond(M)
print("Cond di M:", condM)
PT, L, U = sp.linalg.lu(M)
t, flag = Lsolve(L, PT.T@b)
a, flag = Usolve(U, t)


Cx = -a[0] / 2
Cy = -a[1] / 2
r1 = math.sqrt((a[0]**2) / 4 + (a[1]**2) / 4 - a[2])
t = np.linspace(0, 2 * np.pi, 100)
x = Cx + r1 * np.cos(t)
y = Cy + r1 * np.sin(t)

plt.plot(x, y, 'r-', pxi, pyi, 'bo')
plt.show()


A = np.array([[1, 1, 1], [4, 0, 1], [0, 4, 1], [5.0, 6, 1]])
c1 = np.array([-2, -16, -16, -61.0]).T
pxi1 = np.array([1, 4, 0.0])
pyi1 = np.array([1, 0, 4.0])


def qrLS(A, b):
    n = A.shape[1]
    Q, R = sp.linalg.qr(A)
    h = Q.T@b
    a, flag = Usolve(R[:n, :n], h[:n])
    residuo = np.linalg.norm(h[n:])
    return x, residuo


a1, residuo = qrLS(A, c1)
Cx1 = -a1[0] / 2
Cy1 = -a1[1] / 2
r1_ = math.sqrt((a1[0]**2) / 4 + (a1[1]**2) / 4 - a1[2])
t1 = np.linspace(0, 2 * np.pi, 100)
x1 = Cx1 + r1_ * np.cos(t1)
y1 = Cy1 + r1_ * np.sin(t1)

plt.plot(x1, y1, 'r-', pxi1, pyi1, 'bo')
plt.show()






























