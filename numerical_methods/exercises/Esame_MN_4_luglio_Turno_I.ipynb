{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73aa0225-b2dd-4e47-8ded-3a61037a72c4",
   "metadata": {},
   "source": [
    "## Esame Metodi Numerici  4 Luglio 2024 - Turno I Ore 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18395123-3e72-4667-9f4c-5c98ddd3412d",
   "metadata": {},
   "source": [
    "# Esercizio 1\n",
    "\n",
    "Si consideri il sistema lineare:\n",
    "\n",
    "     A  x = b \n",
    "\n",
    "dove A è la matrice dei coefficienti, b è il termine noto, ed x è il vettore delle incognite da determinare.\n",
    "I dati di questo sistema lineare sono contenuti nel file **testI.mat**.\n",
    "\n",
    "- Si implementino e si testino sui dati forniti due metodi che sono adatti a risolvere tale sistema lineare con le caratteristiche delle matrici dei coefficienti date in input.\n",
    "                                      **[punti 7]**\n",
    "- Si confrontino i risultati ottenuti e si giustifichino utilizzando  e richiamando gli aspetti teorici dei metodi implementati.\n",
    "                                      **[punti 2]**\n",
    "\n",
    "Per la lettura dei dati procedere nel seguente modo:\n",
    "\n",
    "``from scipy.io import loadmat``\n",
    "\n",
    "``import numpy as np``\n",
    "\n",
    "``dati = loadmat('testI')``\n",
    "\n",
    "``A=dati[\"A\"] ``\n",
    "\n",
    "``A=A.astype(float)``\n",
    "\n",
    "`` b=dati[\"b\"] ``\n",
    "\n",
    "`` b=b.astype(float)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "de9b0dad-f548-4b51-99d6-c69d5c2df0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "dati = loadmat('test_4_luglioI')\n",
    "A=dati[\"A\"] \n",
    "A=A.astype(float)\n",
    "b=dati[\"b\"]\n",
    "b=b.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93979213-cb03-4729-9689-a914a6cfd400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A è densa? False\n"
     ]
    }
   ],
   "source": [
    "elemA = np.count_nonzero(A)\n",
    "sizeA = A.size\n",
    "\n",
    "print(\"A è densa?\", elemA / sizeA > 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "88dff814-7b1f-4f95-85dc-7e5715e5c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A,b,x0,toll,it_max):\n",
    "    errore=1000\n",
    "    d=np.diag(A)\n",
    "    n=A.shape[0]\n",
    "    invM=np.diag(1/d)\n",
    "    E=np.tril(A, -1)\n",
    "    F=np.triu(A, 1)\n",
    "    N=-(E + F)\n",
    "    T=invM@N\n",
    "    autovalori=np.linalg.eigvals(T)\n",
    "    raggiospettrale=np.max(np.abs(autovalori))\n",
    "    print(\"raggio spettrale jacobi\", raggiospettrale)\n",
    "    it=0\n",
    "    \n",
    "    er_vet=[]\n",
    "    while it<=it_max and errore>=toll:\n",
    "        x= (N@x0 + b) / d.reshape(n, 1)\n",
    "        errore=np.linalg.norm(x - x0) / np.linalg.norm(x) \n",
    "        er_vet.append(errore)\n",
    "        x0=x.copy()\n",
    "        it=it+1\n",
    "    return x,it,er_vet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a230e59-975a-4206-883a-446425fdd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A,b,x0,toll,it_max):\n",
    "    errore=1000\n",
    "    d=np.diag(A)\n",
    "    D=np.diag(d)\n",
    "    E=np.tril(A, -1)\n",
    "    F=np.triu(A, 1)\n",
    "    M=D + E\n",
    "    N=-F\n",
    "    T=np.linalg.inv(M)@N\n",
    "    autovalori=np.linalg.eigvals(T)\n",
    "    raggiospettrale=np.max(np.abs(autovalori))\n",
    "    print(\"raggio spettrale Gauss-Seidel \",raggiospettrale)\n",
    "    it=0\n",
    "    er_vet=[]\n",
    "    while it<=it_max and errore>=toll:\n",
    "        x=np.linalg.solve(M, N@x0 + b)\n",
    "        errore=np.linalg.norm(x - x0) / np.linalg.norm(x) \n",
    "        er_vet.append(errore)\n",
    "        x0=x.copy()\n",
    "        it=it+1\n",
    "    return x,it,er_vet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a195489-2cba-4cb1-b24a-ca837c733d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raggio spettrale jacobi 0.48209261553629823\n",
      "raggio spettrale Gauss-Seidel  0.28897377801649166\n",
      "Iterazioni jacobi: 38\n",
      "Iterazioni gauss seidel: 23\n"
     ]
    }
   ],
   "source": [
    "tol = 1e-12\n",
    "maxit = 200\n",
    "\n",
    "x0 = np.zeros_like(b)\n",
    "\n",
    "xj, itj, erj = jacobi(A, b, x0, tol, maxit)\n",
    "xgs, itgs, ergs = gauss_seidel(A, b, x0, tol, maxit)\n",
    "\n",
    "print(\"Iterazioni jacobi:\", itj)\n",
    "print(\"Iterazioni gauss seidel:\", itgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342442b-bfe9-47f8-bcbb-f1d53b06742c",
   "metadata": {},
   "source": [
    "Il fattore di convergenza del problema dei metodi per la risoluzione di sistemi lineari iterativi è il raggio spettrale della matrice di iterazione T = (M^-1)*N. Dato che il raggio spettrale di jacobi è maggiore di quello di gauss seidel, gauss seidel convergerà più velocemente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56cdf7-0f5c-4268-ba5d-f1033ee876f0",
   "metadata": {},
   "source": [
    "- Data la matrice\n",
    "$$\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "3.0 & 2.0 & 1.0 & -1.0\\\\\n",
    "4.0 & 6.0 & 3.0 & 2.0\\\\\n",
    "2.0 & 1.0 & 4.0 & 3.0\\\\\n",
    "1.0 & 4.0 & 2.0 & 7.0\n",
    "\\end{array}\n",
    "\\right ],\n",
    "$$\n",
    "calcolarne la fattorizzazione lu di Gauss  facendo uso della funzione scipy.linalg.lu e:\n",
    "- sfruttarla per il calcolo del suo determinante (confrontare l'esattezza del calcolo con quello ottenuto usando la funzione numpy.linalg.det)             **[punti: 2]**\n",
    "- sfruttarla per il calcolo della sua inversa risolvendo n sistemi lineari (confrontare l'inversa con quella ottenuta usando la funzione numpy.linalg.inv)\n",
    "                                                                                                    **[punti: 2]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e85998a9-5389-470e-921f-fb765e19692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolato det con la teoria: 140.0\n",
      "np.linalg.det: 140.00000000000006\n"
     ]
    }
   ],
   "source": [
    "A1 = np.array([[3.0, 2.0, 1.0, -1.0], [4.0, 6.0, 3.0, 2.0], [2.0, 1.0, 4.0, 3.0], [1.0, 4.0, 2.0, 7.0]])\n",
    "\n",
    "P, L, U = sp.linalg.lu(A1)\n",
    "n = A1.shape[0]\n",
    "\n",
    "print(\"Calcolato det con la teoria:\", np.linalg.det(P) * np.prod(np.diag(U)))\n",
    "print(\"np.linalg.det:\", np.linalg.det(A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d4e27556-298d-4d44-b255-c9da1d7939d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolato inv con la teoria:\n",
      " [[ 0.85       -0.45        0.          0.25      ]\n",
      " [-0.39285714  0.39285714 -0.14285714 -0.10714286]\n",
      " [-0.51428571  0.31428571  0.28571429 -0.28571429]\n",
      " [ 0.25       -0.25        0.          0.25      ]]\n",
      "np.linalg.inv:\n",
      " [[ 0.85       -0.45        0.          0.25      ]\n",
      " [-0.39285714  0.39285714 -0.14285714 -0.10714286]\n",
      " [-0.51428571  0.31428571  0.28571429 -0.28571429]\n",
      " [ 0.25       -0.25        0.          0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "I = np.identity(n)\n",
    "x = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    y = np.linalg.solve(L, P@I[:, i])\n",
    "    x[:, i] = np.linalg.solve(U, y)\n",
    "\n",
    "print(\"Calcolato inv con la teoria:\\n\", x)\n",
    "print(\"np.linalg.inv:\\n\", np.linalg.inv(A1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0b8fe-c204-4a42-9bbf-0b338fbdcf8c",
   "metadata": {},
   "source": [
    "## Esercizio 2\n",
    "\n",
    "-  Implementare il  metodo di Newton Raphson, la variante delle corde e la variante di Shamanskii per la soluzione di un sistema non lineare\n",
    "                           [**punti: 7**]\n",
    "\n",
    "- Risolvere il sistema di equazioni non lineare \n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array}{c}\n",
    "x_0\\cdot x_1+x_0=1 \\\\\n",
    " x_0^2+x_1^2=9\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "con ciascuno dei tre metodi e confrontare per ciascun metodo il grafico dell'errore relativo tra due iterati successivi, giustificando i risultati alla luce della teoria. [**punti: 3**]\n",
    "\n",
    " **Nota Bene**: Servirsi del metodo grafico per individuare un \n",
    "iterato iniziale  $X^{(0)}$ nell'intorno della soluzione che si vuole approssimare.  Per fare cio',  visualizzare le \n",
    "curve di livello corrisponenti a z=0 delle due superfici $z_1 = f_1 (x_0 ,x_1 )$ e $z_2 = f_2(x_0 , x_1 )$ e \n",
    "definire come iterato iniziale un vettore $X^{(0)}=(x_0^{(0)},x_1^{(0)})$ oppurtuno le cui componenti appartengono ad un \n",
    "intorno della soluzione (cioè  dei punti di  intersezione tra le curve di livello delle due superfici) \\]\n",
    "\n",
    "- Descrivere teoricamente la variante del Metodo di Newton-Raphson per calcolare il minimo di una funzione non lineare in più variabili.\n",
    "\n",
    " [**punti: 2**]\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a8fd6f94-45a2-4764-b66f-fb8ca5a46858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(initial_guess, F_numerical, J_Numerical, tolX, tolF, max_iterations):\n",
    "    X= np.array(initial_guess, dtype=float)\n",
    "    it=0\n",
    "    erroreF=1+tolF\n",
    "    erroreX=1+tolX\n",
    "    errore=[]\n",
    "    while it < max_iterations and erroreF >= tolF and erroreX >= tolX:\n",
    "        jx = J_Numerical(X[0], X[1])\n",
    "        if np.linalg.det(jx) == 0:\n",
    "            print(\"La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo\")\n",
    "            return None, None,None\n",
    "        fx = F_numerical(X[0], X[1])\n",
    "        fx = fx.squeeze() \n",
    "        Xnew=X + s\n",
    "        normaXnew=np.linalg.norm(Xnew)\n",
    "        if normaXnew !=0:\n",
    "            erroreX=np.linalg.norm(Xnew - X) / np.linalg.norm(X) \n",
    "        else:\n",
    "            erroreX=np.linalg.norm(Xnew - X)\n",
    "        errore.append(erroreX)\n",
    "        fxnew=F_numerical(Xnew[0], Xnew[1])\n",
    "        erroreF= np.linalg.norm(fxnew.squeeze())\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e435fea0-2d09-46ae-ade7-b32d54a3ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson_corde(initial_guess, F_numerical, J_Numerical, tolX, tolF, max_iterations):\n",
    "    X= np.array(initial_guess, dtype=float)\n",
    "    it=0\n",
    "    erroreF=1+tolF\n",
    "    erroreX=1+tolX\n",
    "    errore=[]\n",
    "    while it < max_iterations and erroreF >= tolF and erroreX >= tolX:\n",
    "        if it == 0:\n",
    "            jx = J_Numerical(X[0], X[1])\n",
    "            if np.linalg.det(jx) == 0:\n",
    "                print(\"La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo\")\n",
    "                return None, None,None\n",
    "        fx = F_numerical(X[0], X[1])\n",
    "        fx = fx.squeeze() \n",
    "        s = np.linalg.solve(jx, -fx)\n",
    "        Xnew=X + s\n",
    "        normaXnew=np.linalg.norm(Xnew)\n",
    "        if normaXnew !=0:\n",
    "            erroreX=np.linalg.norm(Xnew - X) / np.linalg.norm(X) \n",
    "        else:\n",
    "            erroreX=np.linalg.norm(Xnew - X)\n",
    "        errore.append(erroreX)\n",
    "        fxnew=F_numerical(Xnew[0], Xnew[1])\n",
    "        erroreF= np.linalg.norm(fxnew.squeeze())\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b0d44b26-9ea8-40f4-8581-814083645d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson_sham(initial_guess, update, F_numerical, J_Numerical, tolX, tolF, max_iterations):\n",
    "    X= np.array(initial_guess, dtype=float)\n",
    "    it=0\n",
    "    erroreF=1+tolF\n",
    "    erroreX=1+tolX\n",
    "    errore=[]\n",
    "    while it < max_iterations and erroreF >= tolF and erroreX >= tolX:\n",
    "        if it % update:\n",
    "            jx = J_Numerical(X[0], X[1])\n",
    "            if np.linalg.det(jx) == 0:\n",
    "                print(\"La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo\")\n",
    "                return None, None,None\n",
    "        fx = F_numerical(X[0], X[1])\n",
    "        fx = fx.squeeze() \n",
    "        s = np.linalg.solve(jx, -fx)\n",
    "        Xnew=X + s\n",
    "        normaXnew=np.linalg.norm(Xnew)\n",
    "        if normaXnew !=0:\n",
    "            erroreX=np.linalg.norm(Xnew - X) / np.linalg.norm(X) \n",
    "        else:\n",
    "            erroreX=np.linalg.norm(Xnew - X)\n",
    "        errore.append(erroreX)\n",
    "        fxnew=F_numerical(Xnew[0], Xnew[1])\n",
    "        erroreF= np.linalg.norm(fxnew.squeeze())\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,errore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3945c-db1a-4b49-b80b-cc12c5330e68",
   "metadata": {},
   "source": [
    "## Domande Intelligenza Artificiale\n",
    "**NB: Ogni risposta esatta:  +0.5 punti, ogni risposta errata: -0.5 punti. La mancanza di risposta:  0 punti**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e415e-dc1f-42b0-aa27-cb4a046582c5",
   "metadata": {},
   "source": [
    "Domande a risposta multipla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff34e78-5769-41bc-9983-e25fc55eb18f",
   "metadata": {},
   "source": [
    "**1.** Quali sono i passaggi fondamentali all’interno del paradigma generale dell’Intelligenza Artificiale?\n",
    "\n",
    "•\tAcquisizione dati, Data Processing, Addestramento del modello, Predizione e metriche\n",
    "\n",
    "•\tData Processing, Addestramento del Modello, Predizione, Analisi economica dei risultati\n",
    "\n",
    "•\tAcquisizione dati, Data Processing, Addestramento del modello, Predizione, Test di Turing\n",
    "\n",
    "•\tAcquisizione dati, Addestramento del Modello, Test di Turing, Predizione\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474e22e-e367-4289-8a1c-ed104eb111c6",
   "metadata": {},
   "source": [
    "**2.** Per una rete neurale, l’apprendimento è legato a:\n",
    "\n",
    "•\tMinimizzare la funzione obiettivo\n",
    "\n",
    "•\tMinimizzare la funzione di attivazione\n",
    "\n",
    "•\tMassimizzare il valore dei pesi tramite l’algoritmo di back-propagation\n",
    "\n",
    "•\tMassimizzare il valore della funzione di training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328706ff-0d3c-4b99-97f3-d2eea5158c0c",
   "metadata": {},
   "source": [
    "**3.**  Il Test di Turing serve a:\n",
    "\n",
    "•\tValutare se una macchina dimostra un comportamento intelligente\n",
    "\n",
    "•\tValutare il carico computazionale di un algoritmo di Intelligenza Artificiale\n",
    "\n",
    "•\tValutare la velocità di risposta di un algoritmo di Intelligenza Artificiale\n",
    "\n",
    "•\tValutare se una macchina dimostra un comportamento predicibile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248323f7-7a5a-478b-b446-71db7d2ff490",
   "metadata": {},
   "source": [
    "**4.**\n",
    "Le ultime e più recenti innovazioni nel campo dell’Intelligenza Artificiale sono:\n",
    "\n",
    "•\tCNN, GAN e Transformers\n",
    "\n",
    "•\tExpert Systems, CNN e GAN\n",
    "\n",
    "•\tExpert Systems, Deep Learning e CNN\n",
    "\n",
    "•\tCNN, Expert Systems e Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab76c03-ab08-49b8-a688-688ca2aa7cbe",
   "metadata": {},
   "source": [
    "**5.** A cosa serve il validation set?\n",
    "\n",
    "•\tA trovare i migliori iperparametri del modello\n",
    "\n",
    "•\tAd addestrare il modello \n",
    "\n",
    "•\tA testare il modello\n",
    "\n",
    "•\tA trovare le etichette dei dati di input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ecaab-5021-450a-90d5-720082587ddb",
   "metadata": {},
   "source": [
    "**Domande aperte**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9bcf40-f194-4892-ad65-a2055d694430",
   "metadata": {},
   "source": [
    "Quale è il ruolo del learning rate nella formula di aggiornamento dei pesi mediante gradient descent. Aggiornamento del learning rate programmato (learning rate scheduling) : step decay, decadimento esponenziale, decadimento dipendente dal tempo. **[punti 2]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f184854-745b-413a-b707-026d69441abd",
   "metadata": {},
   "source": [
    "\n",
    "Learning rate adattivo per ogni peso (durante il processo di ottimizzazione) : Adagrad, RMSProp, Adadelta, Adam. (formula di aggiornamento dei pesi e discussioni)\n",
    "**[punti 2.5]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fca09-a7e4-4fc2-9dcb-f052a31248e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0059e44-327a-4719-9efd-0712adb082ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
